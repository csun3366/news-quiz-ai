import os
import sys
import django
import requests
from bs4 import BeautifulSoup
from datetime import datetime

# Django è¨­å®š
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')
django.setup()

from core.models import Article


def fetch_bbc_from_rss(category='world', limit=10):
    rss_feeds = {
        'world': 'http://feeds.bbci.co.uk/news/world/rss.xml',
        'business': 'http://feeds.bbci.co.uk/news/business/rss.xml',
        'technology': 'http://feeds.bbci.co.uk/news/technology/rss.xml',
        'entertainment_and_arts': 'http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml',
        'sport': 'http://feeds.bbci.co.uk/sport/rss.xml',
    }

    feed_url = rss_feeds.get(category)
    if not feed_url:
        print(f"âŒ ä¸æ”¯æ´çš„åˆ†é¡ï¼š{category}")
        return

    print(f"ğŸŒ æ­£åœ¨é€é RSS çˆ¬å– BBC åˆ†é¡ï¼š{category} ...")
    res = requests.get(feed_url)
    soup = BeautifulSoup(res.content, 'xml')
    items = soup.find_all('item')[:limit]

    added = 0
    for item in items:
        title = item.title.get_text(strip=True)
        link = item.link.get_text(strip=True)

        if Article.objects.filter(title=title).exists() or Article.objects.filter(url=link).exists():
            print(f"âš ï¸ å·²å­˜åœ¨ï¼Œè·³éï¼š{title}")
            continue

        try:
            article_res = requests.get(link)
            article_soup = BeautifulSoup(article_res.text, 'html.parser')
            paragraphs = article_soup.select("main p") or article_soup.select("article p")
            content = '\n'.join(p.get_text(strip=True) for p in paragraphs)
        except Exception as e:
            print(f"âš ï¸ æŠ“å–å¤±æ•—ï¼š{title}ï¼ŒéŒ¯èª¤ï¼š{e}")
            continue

        if not content.strip():
            print(f"âš ï¸ æ–‡ç« å…§å®¹ç‚ºç©ºï¼Œè·³éï¼š{title}")
            continue

        summary = content[:150] + '...' if len(content) > 150 else content

        Article.objects.create(
            title=title,
            summary=summary,
            content=content,
            url=link,
            source='BBC',
            category=category,
            published_at=datetime.now()
        )
        added += 1
        print(f"âœ… æ–°å¢æ–‡ç« ï¼š{title}")

    print(f"ğŸ¯ BBC {category} RSS å®Œæˆï¼Œå…±æ–°å¢ {added} ç¯‡æ–‡ç« ã€‚")


if __name__ == '__main__':
    categories = ['world', 'business', 'technology', 'entertainment_and_arts', 'sport']
    for cat in categories:
        fetch_bbc_from_rss(category=cat, limit=10)
